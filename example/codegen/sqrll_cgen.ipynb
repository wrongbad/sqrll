{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params=4,468,736\n",
      "loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sqrll.sqrllm import SqrLLM, StatefulWrapper\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "model = SqrLLM(\n",
    "    n_embed = 256,\n",
    "    n_mem = 512,\n",
    "    n_ffn = 256,\n",
    "    ffn_rate = 4,\n",
    "    n_layer = 6,\n",
    ")\n",
    "smodel = StatefulWrapper(model)\n",
    "\n",
    "params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{params=:,}')\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(f'../models/model{params}.pt'))\n",
    "    print('loaded')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqrll import sqrll, sqrllm\n",
    "\n",
    "class CustomTracer(torch.fx.Tracer):\n",
    "    def is_leaf_module(self, mod, name):\n",
    "        return False\n",
    "\n",
    "tracer = CustomTracer(autowrap_functions=[\n",
    "    sqrll.sqrll_kernel,\n",
    "    sqrllm.rms_norm,\n",
    "])\n",
    "\n",
    "graph = tracer.trace(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.fx import map_arg\n",
    "import operator\n",
    "\n",
    "def shape_dtype(shape, ref=False, const=False):\n",
    "    shape = ','.join(str(d) for d in shape)\n",
    "    dtype = f'ml::tensor<{shape}>'\n",
    "    if ref:\n",
    "        dtype += '&'\n",
    "    if const:\n",
    "        dtype = 'const '+dtype\n",
    "    return dtype\n",
    "\n",
    "def val_dtype(val, ref=False, const=False):\n",
    "    if isinstance(val, (list, tuple)):\n",
    "        subtypes = [val_dtype(a, ref, const) for a in val]\n",
    "        subtypes = ','.join(subtypes)\n",
    "        return f'std::tuple<{subtypes}>'\n",
    "    return shape_dtype(tuple(val.shape), ref, const)\n",
    "\n",
    "def flatten(val):\n",
    "    if isinstance(val, (list, tuple)):\n",
    "        return [a for vx in val for a in flatten(vx)]\n",
    "    return [val]\n",
    "\n",
    "        \n",
    "class Interpreter(torch.fx.Interpreter):\n",
    "    inputs = {}\n",
    "    output_type = None\n",
    "    output_ref = None\n",
    "    weights = {}\n",
    "\n",
    "    tmp_vars = {}\n",
    "    node_vars = {}\n",
    "\n",
    "    fwds = []\n",
    "\n",
    "    def get_tmp(self, node, shape):\n",
    "        refcount = len(node.users)\n",
    "        for name, info in self.tmp_vars.items():\n",
    "            tshape, tref = info\n",
    "            if shape == tshape and tref == 0:\n",
    "                self.node_vars[node] = name\n",
    "                info[1] = refcount\n",
    "                return name\n",
    "        name = f'tmp{len(self.tmp_vars)}'\n",
    "        self.tmp_vars[name] = [shape, refcount]\n",
    "        self.node_vars[node] = name\n",
    "        return name\n",
    "\n",
    "    def deref(self, node):\n",
    "        if node is None:\n",
    "            return 'nullptr'\n",
    "        if isinstance(node, slice):\n",
    "            if node == slice(None, None, None):\n",
    "                return 'slice<>()'\n",
    "            else:\n",
    "                raise ValueError('unsupported '+str(node))\n",
    "        if not isinstance(node, torch.fx.Node):\n",
    "            return str(node)\n",
    "        if node not in self.node_vars:\n",
    "            return node.name\n",
    "        name = self.node_vars[node]\n",
    "        if name in self.tmp_vars:\n",
    "            self.tmp_vars[name][1] -= 1\n",
    "            assert self.tmp_vars[name][1] >= 0\n",
    "        return name\n",
    "\n",
    "    def nested_refstr(self, arg):\n",
    "        if isinstance(arg, (list, tuple)):\n",
    "            nest = [self.nested_refstr(a) for a in arg]\n",
    "            return '{'+', '.join(nest)+'}'\n",
    "        return self.node_vars[arg]\n",
    "\n",
    "    def alias(self, node, src):\n",
    "        src = self.node_vars[src]\n",
    "        self.node_vars[node] = src\n",
    "        self.tmp_vars[src][1] += len(node.users) - 1\n",
    "\n",
    "\n",
    "    def run_node(self, n):\n",
    "        with self._set_current_node(n):\n",
    "\n",
    "            args, kwargs = self.fetch_args_kwargs_from_env(n)\n",
    "            val = getattr(self, n.op)(n.target, args, kwargs)\n",
    "\n",
    "            if n.op == 'placeholder':\n",
    "                self.inputs[n.name] = val_dtype(val)\n",
    "                self.node_vars[n] = n.name\n",
    "            elif n.op == 'get_attr':\n",
    "                self.weights[n.name] = (val_dtype(val, const=True), val)\n",
    "                self.node_vars[n] = n.name\n",
    "            elif n.op == 'call_function' or n.op == 'call_method':\n",
    "\n",
    "                fname = n.target\n",
    "                if 'fun' in n.op:\n",
    "                    fname = fname.__name__\n",
    "\n",
    "                if n.target == operator.getitem:\n",
    "                    if isinstance(args[0], (list, tuple)):\n",
    "                        src = self.node_vars[n.args[0]]\n",
    "                        self.node_vars[n] = f'get<{args[1]}>({src})'\n",
    "                        return val\n",
    "                \n",
    "                no_ops = [\n",
    "                    'detach',\n",
    "                    'clone',\n",
    "                    torch.nn.functional.dropout,\n",
    "                ]\n",
    "                if n.target in no_ops:\n",
    "                    self.alias(n, n.args[0])\n",
    "                    return val\n",
    "\n",
    "                out_var = self.get_tmp(n, tuple(val.shape))\n",
    "                flat_arg_nodes = flatten(n.args)\n",
    "                flat_arg_vars = [self.deref(n) for n in flat_arg_nodes]\n",
    "                fargs = ', '.join(flat_arg_vars)\n",
    "\n",
    "                self.fwds += [f'{out_var} = {fname}({fargs})']\n",
    "            elif n.op == 'call_module':\n",
    "                raise ValueError('call_module unsupported')\n",
    "            elif n.op == 'output':\n",
    "                self.output_type = val_dtype(val, ref=True)\n",
    "                self.output_ref = self.nested_refstr(n.args[0])\n",
    "            else:\n",
    "                print(n.name, ':', n.op, n.target, n.args, n.kwargs)\n",
    "                print('->', getattr(val, 'shape', f'{len(val)=}'), len(n.users))\n",
    "\n",
    "            return val\n",
    "\n",
    "\n",
    "inputs = torch.tensor([[ord('a')]])\n",
    "_, mem = model(inputs)\n",
    "mem = [torch.zeros_like(m) for m in mem]\n",
    "\n",
    "interp = Interpreter(model, graph=graph)\n",
    "\n",
    "out = interp.run(inputs, mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurable names, for C global namespacing\n",
    "class_name = 'Model'\n",
    "prefix = 'model'\n",
    "filename = 'artifacts/model.cpp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = []\n",
    "ivars = []\n",
    "fwds = []\n",
    "\n",
    "for name, info in interp.weights.items():\n",
    "    dtype, val = info\n",
    "    offset = len(blob)\n",
    "    blob += val.bfloat16().view(torch.uint16).flatten().tolist()\n",
    "    ivars += [f'static {dtype} {name} {{ blob+{offset} }}']\n",
    "\n",
    "fwds += interp.fwds\n",
    "\n",
    "class Writer:\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "        self.indent = 0\n",
    "\n",
    "    def __call__(self, s, nl='\\n'):\n",
    "        self.f.write(' ' * self.indent)\n",
    "        self.f.write(s + nl)\n",
    "        return self\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.__call__('{')\n",
    "        self.indent += 4\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *_):\n",
    "        self.indent -= 4\n",
    "        self.__call__('}', '')\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    w = Writer(f)\n",
    "    w('#include \"cgen_math.h\"\\n')\n",
    "\n",
    "    w('// weight initializers\"')\n",
    "    with w(f'static const ml::bfloat16 blob[{len(blob)}] = '):\n",
    "        w(','.join([hex(x) for x in blob]))\n",
    "    w(';')\n",
    "    \n",
    "    w('// weight tensors')\n",
    "    for i in ivars:\n",
    "        w(i + ';')\n",
    "    w('')\n",
    "\n",
    "    with w(f'struct {class_name}'):\n",
    "\n",
    "        w('// inputs')\n",
    "        for name, dtype in interp.inputs.items():\n",
    "            w(f'{dtype} {name};')\n",
    "        w('')\n",
    "            \n",
    "        w('// tmp vars')\n",
    "        for name, info in interp.tmp_vars.items():\n",
    "            dtype = shape_dtype(info[0])\n",
    "            w(f'{dtype} {name};')\n",
    "        w('')\n",
    "\n",
    "        w(f'{interp.output_type}')\n",
    "        with w('operator()()'):\n",
    "            \n",
    "            w('using std::get;')\n",
    "            w('using namespace ml;')\n",
    "                \n",
    "            for f in fwds:\n",
    "                w(f + ';')\n",
    "\n",
    "            w(f'return {interp.output_ref};')\n",
    "\n",
    "        w('')\n",
    "\n",
    "    w(';\\n\\n')\n",
    "\n",
    "    with w('namespace'):\n",
    "        w(f'ml::rng64 g_rng;')\n",
    "        w(f'{class_name} g_model;')\n",
    "    w('')\n",
    "\n",
    "    w(f'''\n",
    "extern \"C\"\n",
    "int {prefix}_step(int prevtok, int numout, float temperature)\n",
    "{{\n",
    "    g_model.x.ptr()[0] = prevtok;\n",
    "    auto outs = g_model();\n",
    "    g_model.mem = std::get<1>(outs);\n",
    "\n",
    "    auto & logits = std::get<0>(outs);\n",
    "    numout = std::min(numout, logits.numel());\n",
    "    return ml::sample_(logits.ptr(), numout, g_rng, temperature);\n",
    "}}\n",
    "extern \"C\"\n",
    "void {prefix}_reset()\n",
    "{{\n",
    "    std::apply([] (auto &&... x) {{ (x.zero_(), ...); }}, g_model.mem);\n",
    "}}\n",
    "''')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
