{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params=4,468,736\n",
      "loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sqrll.sqrllm import SqrLLM, StatefulWrapper\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "model = SqrLLM(\n",
    "    n_embed = 256,\n",
    "    n_mem = 512,\n",
    "    n_ffn = 256,\n",
    "    ffn_rate = 4,\n",
    "    n_layer = 6,\n",
    ")\n",
    "smodel = StatefulWrapper(model)\n",
    "\n",
    "params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{params=:,}')\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(f'./model{params}.pt'))\n",
    "    print('loaded')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model.eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqrll import sqrll, sqrllm\n",
    "\n",
    "class CustomTracer(torch.fx.Tracer):\n",
    "    def is_leaf_module(self, mod, name):\n",
    "        # if isinstance(mod, sqrllm.RmsNorm):\n",
    "        #     return True\n",
    "        # print('isleaf', mod.__class__, name)\n",
    "        return False\n",
    "\n",
    "tracer = CustomTracer(autowrap_functions=[\n",
    "    sqrll.sqrll_kernel,\n",
    "    sqrllm.rms_norm,\n",
    "])\n",
    "\n",
    "graph = tracer.trace(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.fx import map_arg\n",
    "import operator\n",
    "\n",
    "class Interpreter(torch.fx.Interpreter):\n",
    "    inputs = {}\n",
    "    outputs = {}\n",
    "    weights = {}\n",
    "\n",
    "    varmap = {}\n",
    "    tempvars = []\n",
    "\n",
    "    fwds = []\n",
    "\n",
    "    # def map_nodes_to_values(self, args, n):\n",
    "    #     def load_arg(n_arg):\n",
    "    #         if n_arg in self.varmap:\n",
    "    #             self.tempvars[self.varmap[n_arg]][1] -= 1\n",
    "    #         else:\n",
    "    #             print('load', n_arg, {k: self.tempvars[v] for k,v in self.varmap.items()})\n",
    "    #         return self.env[n_arg]\n",
    "    #     return map_arg(args, load_arg)\n",
    "\n",
    "    def run_node(self, n):\n",
    "        with self._set_current_node(n):\n",
    "\n",
    "            args, kwargs = self.fetch_args_kwargs_from_env(n)\n",
    "            val = getattr(self, n.op)(n.target, args, kwargs)\n",
    "\n",
    "            # print(n.name, ':', n.op, n.target, n.args, n.kwargs)\n",
    "            # print('->', getattr(val, 'shape', f'{len(val)=}'), len(n.users))\n",
    "\n",
    "            def flatten(x):\n",
    "                if isinstance(x, (list, tuple)):\n",
    "                    return [a for xi in x for a in flatten(xi)]\n",
    "                return [x]\n",
    "\n",
    "            if 'call' in n.op:\n",
    "                shape = tuple(val.squeeze().shape)\n",
    "                n_users = len(n.users)\n",
    "\n",
    "                for i, v in enumerate(self.tempvars):\n",
    "                    if v[0] == shape and v[1] == 0:\n",
    "                        self.varmap[n] = i\n",
    "                        v[1] = n_users\n",
    "                        break\n",
    "                else:\n",
    "                    self.varmap[n] = len(self.tempvars)\n",
    "                    self.tempvars += [[shape, n_users]]\n",
    "\n",
    "            # deref after alloc to be safe against aliasing\n",
    "\n",
    "            def deref_arg(n_arg):\n",
    "                if n_arg in self.varmap:\n",
    "                    self.tempvars[self.varmap[n_arg]][1] -= 1\n",
    "            map_arg(n.args, deref_arg)\n",
    "            map_arg(n.kwargs, deref_arg)\n",
    "\n",
    "\n",
    "\n",
    "            def argstr(n):\n",
    "                return ', '.join([getattr(a,'name',str(a)) for a in n.args if a is not None])\n",
    "\n",
    "            if n.op == 'get_attr':\n",
    "                self.weights[n.name] = val.squeeze()\n",
    "            elif n.op == 'placeholder':\n",
    "                # TODO arbitrary nesting\n",
    "                if isinstance(val, list):\n",
    "                    for i, v in enumerate(val):\n",
    "                        shape = tuple(v.squeeze().shape)\n",
    "                        self.inputs[f'{n.name}{i}'] = shape\n",
    "                else:\n",
    "                    shape = tuple(val.squeeze().shape)\n",
    "                    self.inputs[n.name] = shape\n",
    "            elif n.op == 'output':\n",
    "                out_vals = flatten(args)\n",
    "                out_vars = flatten(n.args)\n",
    "                for i, x in enumerate(zip(out_vals, out_vars)):\n",
    "                    dst, src = x\n",
    "                    shape = tuple(dst.squeeze().shape)\n",
    "                    name = f'{n.name}{i}' if len(out_vals)>1 else n.name\n",
    "                    self.outputs[name] = shape\n",
    "                    self.fwds += [f'ml::copy({name}, {src})']\n",
    "            elif n.op == 'call_method':\n",
    "                if n.target == 'clone':\n",
    "                    self.fwds += [f'ml::copy({n.name}, {argstr(n)})']\n",
    "                elif n.target == 'detach':\n",
    "                    self.fwds += [f'ml::copy({n.name}, {argstr(n)})']\n",
    "                elif n.target == 'sigmoid':\n",
    "                    self.fwds += [f'ml::sigmoid({n.name}, {argstr(n)})']\n",
    "                else:\n",
    "                    print(n.name, ':', n.op, n.target, n.args, n.kwargs)\n",
    "                    print('->', getattr(val, 'shape', f'{len(val)=}'), len(n.users))\n",
    "            elif n.op == 'call_function':\n",
    "                if n.target == operator.add:\n",
    "                    self.fwds += [f'ml::add({n.name}, {argstr(n)})']\n",
    "                elif n.target == operator.mul:\n",
    "                    self.fwds += [f'ml::mul({n.name}, {argstr(n)})']\n",
    "                elif n.target == operator.getitem:\n",
    "                    if isinstance(args[0], list):\n",
    "                        src = f'{n.args[0]}{args[1]}'\n",
    "                        self.fwds += [f'ml::copy({n.name}, {src})']\n",
    "                    elif isinstance(args[0], torch.Tensor):\n",
    "                        # idx = []\n",
    "                        # for i in args[1]:\n",
    "                        #     idx += [str(i)]\n",
    "                        # idx = ', '.join(idx)\n",
    "                        # self.fwds += [f'ml::slice({n.name}, {n.args[0]}, {idx})']\n",
    "                        # XXX in sqrll 1-step mode this is a no-op slice\n",
    "                        self.fwds += [f'ml::copy({n.name}, {n.args[0]})']\n",
    "                    else:\n",
    "                        print(n.name, ':', n.op, n.target, n.args, n.kwargs)\n",
    "                        print('->', getattr(val, 'shape', f'{len(val)=}'), len(n.users))\n",
    "                elif n.target == torch.nn.functional.linear:\n",
    "                    self.fwds += [f'ml::linear({n.name}, {argstr(n)})']\n",
    "                elif n.target == torch.nn.functional.softsign:\n",
    "                    self.fwds += [f'ml::softsign({n.name}, {argstr(n)})']\n",
    "                elif n.target == torch.nn.functional.embedding:\n",
    "                    self.fwds += [f'ml::embedding({n.name}, {argstr(n)})']\n",
    "                elif n.target == torch.nn.functional.dropout:\n",
    "                    self.fwds += [f'ml::copy({n.name}, {argstr(n)})']\n",
    "                elif n.target == sqrll.sqrll_kernel:\n",
    "                    self.fwds += [f'ml::sqrll({n.name}, {argstr(n)})']\n",
    "                elif n.target == sqrllm.rms_norm:\n",
    "                    self.fwds += [f'ml::rmsnorm({n.name}, {argstr(n)})']\n",
    "                else:\n",
    "                    print(n.target, n.target.__name__, n.target.__qualname__, n.target.__module__)\n",
    "                    print(n.name, ':', n.op, n.target, n.args, n.kwargs)\n",
    "                    print('->', getattr(val, 'shape', f'{len(val)=}'), len(n.users))\n",
    "            elif n.op == 'call_module':\n",
    "                if n.target.__class__ == sqrllm.RmsNorm:\n",
    "                    self.fwds += [f'ml::rmsnorm({n.name}, {argstr(n)})']\n",
    "                else:\n",
    "                    print(n.target, n.target.__class__)\n",
    "                    print(n.name, ':', n.op, n.target, n.args, n.kwargs)\n",
    "                    print('->', getattr(val, 'shape', f'{len(val)=}'), len(n.users))\n",
    "            else:\n",
    "                print(n.name, ':', n.op, n.target, n.args, n.kwargs)\n",
    "                print('->', getattr(val, 'shape', f'{len(val)=}'), len(n.users))\n",
    "            # print(\"\")\n",
    "            return val\n",
    "\n",
    "\n",
    "inputs = torch.tensor([[0]])\n",
    "_, mem = model(inputs)\n",
    "mem = [torch.zeros_like(m) for m in mem]\n",
    "\n",
    "interp = Interpreter(model, graph=graph)\n",
    "\n",
    "out = interp.run(inputs, mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = []\n",
    "ivars = []\n",
    "fwds = []\n",
    "\n",
    "def shapetype(shape, const=False):\n",
    "    qual = ' const' if const else ''\n",
    "    if len(shape) == 0:\n",
    "        return f'Vec<1>{qual}'\n",
    "    if len(shape) == 1:\n",
    "        return f'Vec<{shape[0]}>{qual}'\n",
    "    elif len(shape) == 2:\n",
    "        return f'Mat<{shape[0]}, {shape[1]}>{qual}'\n",
    "    else:\n",
    "        assert 0, shape\n",
    "    \n",
    "def store(name, val, const=True):\n",
    "    global blob\n",
    "    global ivars\n",
    "    offset = len(blob)\n",
    "    blob += val.bfloat16().view(torch.uint16).flatten().tolist()\n",
    "    shape = list(val.shape)\n",
    "    stype = shapetype(shape, const)\n",
    "    ivars += [f'{stype} {name} {{ blob, {offset} }}']\n",
    "    return name, *shape\n",
    "\n",
    "def addvar(name, shape, const=False):\n",
    "    global blob\n",
    "    global ivars\n",
    "    stype = shapetype(shape, const)\n",
    "    ivars += [f'{stype} {name} {{ Zeros{{}} }}']\n",
    "\n",
    "\n",
    "for name, value in interp.weights.items():\n",
    "    store(name, value, const=True)\n",
    "    \n",
    "for i, v in enumerate(interp.tempvars):\n",
    "    name = f'tmp{i}'\n",
    "    addvar(name, shape=v[0], const=False)\n",
    "\n",
    "for k, i in interp.varmap.items():\n",
    "    shape = interp.tempvars[i][0]\n",
    "    stype = shapetype(shape)\n",
    "    ivars += [f'{stype} & {k} = tmp{i}']\n",
    "\n",
    "for name, shape in interp.inputs.items():\n",
    "    stype = shapetype(shape)\n",
    "    ivars += [f'{stype} {name} {{ Zeros{{}} }}']\n",
    "\n",
    "for name, shape in interp.outputs.items():\n",
    "    stype = shapetype(shape, const=True)\n",
    "    ivars += [f'{stype} {name} {{ Zeros{{}} }}']\n",
    "\n",
    "fwds += interp.fwds\n",
    "\n",
    "# ivars += [f'Sampler<256> sampler {{ out.out }}']\n",
    "fwds += ['int out = prev']\n",
    "fwds += ['return out']\n",
    "\n",
    "\n",
    "class Writer:\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "        self.indent = 0\n",
    "\n",
    "    def __call__(self, s):\n",
    "        self.f.write(' '*self.indent)\n",
    "        self.f.write(s)\n",
    "        return self\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.f.write('\\n')\n",
    "        self.indent += 4\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *_):\n",
    "        self.indent -= 4\n",
    "\n",
    "\n",
    "with open('model.cpp', 'w') as f:\n",
    "    w = Writer(f)\n",
    "    w('#include \"cgen_head.h\"\\n\\n')\n",
    "\n",
    "    with w(f'BFloat16Blob<{len(blob)}> blob = {{'):\n",
    "        w(','.join([hex(x) for x in blob]) + '\\n')\n",
    "    w('};\\n\\n')\n",
    "\n",
    "    with w('struct Model {\\n'):\n",
    "        for i in ivars:\n",
    "            w(i + ';\\n')\n",
    "\n",
    "        w('\\n')\n",
    "        with w('int step(int prev) {'):\n",
    "            for f in fwds:\n",
    "                w(f + ';\\n')\n",
    "        w('}\\n')\n",
    "\n",
    "    w('};\\n\\n')\n",
    "    w('Model model;\\n\\n')\n",
    "    w('#include \"cgen_main.h\"\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = []\n",
    "ivars = []\n",
    "fwds = []\n",
    "\n",
    "def store(name, val):\n",
    "    global blob\n",
    "    global ivars\n",
    "    offset = len(blob)\n",
    "    blob += val.bfloat16().view(torch.uint16).flatten().tolist()\n",
    "    shape = list(val.shape)\n",
    "    if len(shape) == 1:\n",
    "        ivars += [f'Vec<{shape[0]}> {name} {{ blob, {offset} }}']\n",
    "    elif len(shape) == 2:\n",
    "        ivars += [f'Mat<{shape[0]}, {shape[1]}> {name} {{ blob, {offset} }}']\n",
    "    else:\n",
    "        assert 0\n",
    "    return name, *shape\n",
    "\n",
    "\n",
    "name, h, w = store('embed_w', model.w_in.weight);\n",
    "ivars += [f'Embed<{h},{w}> embed {{ {name} }}']\n",
    "fwds += ['embed(prev)']\n",
    "\n",
    "last_out = 'embed.out'\n",
    "for i, lay in enumerate(model.sqrll.blocks):\n",
    "\n",
    "    s, w = store(f'l{i}_norm_s', lay.norm.weight)\n",
    "    b, _ = store(f'l{i}_norm_b', lay.norm.bias)\n",
    "    ivars += [f'VecMulAdd<{w}> l{i}_norm {{ {last_out}, {s}, {b} }}']\n",
    "    fwds += [f'l{i}_norm()']\n",
    "\n",
    "    ivars += [f'VecAdd<{w}> l{i}_res {{ {last_out}, l{i}_norm.out }}']\n",
    "    fwds += [f'l{i}_res()']\n",
    "\n",
    "    if hasattr(lay, 'ffn'):\n",
    "        f = lay.ffn\n",
    "\n",
    "        s, w = store(f'l{i}_norm2_s', f.norm.weight)\n",
    "        b, _ = store(f'l{i}_norm2_b', f.norm.bias)\n",
    "        ivars += [f'VecMulAdd<{w}> l{i}_norm2 {{ {last_out}, {s}, {b} }}']\n",
    "        fwds += [f'l{i}_norm2()']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    last_out = f'l{i}_res.out'\n",
    "    \n",
    "\n",
    "    \n",
    "m, h, w = store('out_w', model.w_out.weight)\n",
    "b, _ = store('out_b', model.w_out.bias)\n",
    "ivars += [f'VecMatBias<{h},{w}> out {{ {last_out}, {m}, {b} }}']\n",
    "fwds += ['out()']\n",
    "\n",
    "ivars += [f'Sampler<{w}> sampler {{ out.out }}']\n",
    "fwds += ['int out = sampler()']\n",
    "fwds += ['return out']\n",
    "\n",
    "\n",
    "class Writer:\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "        self.indent = 0\n",
    "\n",
    "    def __call__(self, s):\n",
    "        self.f.write(' '*self.indent)\n",
    "        self.f.write(s)\n",
    "        return self\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.f.write('\\n')\n",
    "        self.indent += 4\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *_):\n",
    "        self.indent -= 4\n",
    "\n",
    "\n",
    "with open('model.cpp', 'w') as f:\n",
    "    w = Writer(f)\n",
    "    w('#include \"cgen_head.h\"\\n\\n')\n",
    "\n",
    "    with w(f'BFloat16Blob<{len(blob)}> blob = {{'):\n",
    "        w(','.join([hex(x) for x in blob]) + '\\n')\n",
    "    w('};\\n\\n')\n",
    "\n",
    "    with w('struct Model {\\n'):\n",
    "        for i in ivars:\n",
    "            w(i + ';\\n')\n",
    "\n",
    "        w('\\n')\n",
    "        with w('int step(int prev) {'):\n",
    "            for f in fwds:\n",
    "                w(f + ';\\n')\n",
    "        w('}\\n')\n",
    "\n",
    "    w('};\\n\\n')\n",
    "    w('Model model;\\n\\n')\n",
    "    w('#include \"cgen_main.h\"\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
