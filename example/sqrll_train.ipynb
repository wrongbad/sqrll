{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "params=19,118,848\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sqrll.sqrllm import SqrLLM\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "device = torch.device('cuda')\n",
    "dtype = torch.float32\n",
    "\n",
    "model = SqrLLM(\n",
    "    n_embed = 384,\n",
    "    n_mem = 512,\n",
    "    n_layer = 12,\n",
    ").float().to(device)\n",
    "\n",
    "params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{params=:,}')\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(f'./model{params}.pt'))\n",
    "    print('loaded')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_iter(fname='finnegans_wake.txt', chunk=8192):\n",
    "    for _ in range(10):\n",
    "        with open(fname, 'rb') as f:\n",
    "            while len(x := f.read(chunk)) == chunk:\n",
    "                x = torch.frombuffer(x, dtype=torch.uint8)\n",
    "                yield x.to(device).long()\n",
    "\n",
    "def shuf_iter(src=file_iter(), bufsize=512):\n",
    "    buffer = [None] * bufsize\n",
    "    for x in src:\n",
    "        i = torch.randint(0, bufsize, ())\n",
    "        out = buffer[i]\n",
    "        buffer[i] = x\n",
    "        if out is not None:\n",
    "            yield out\n",
    "    for out in buffer:\n",
    "        if out is not None:\n",
    "            yield out\n",
    "\n",
    "def batch_iter(src=shuf_iter(), batch=4):\n",
    "    buf = []\n",
    "    for x in src:\n",
    "        buf += [x]\n",
    "        if len(buf) == batch:\n",
    "            yield torch.stack(buf)\n",
    "            buf = []\n",
    "\n",
    "def train_iter(src=batch_iter(), chunk=512):\n",
    "    for x in src:\n",
    "        for o in range(0, x.shape[1]-chunk+1, chunk):\n",
    "            yield x[:, o:o+chunk]\n",
    "\n",
    "trainset = train_iter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17e648fe4c04f6aac52b4e04a55c290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'type': 'scatter', 'uid': '9efffecc-fb74-411d-8263-59aa1d75b974'}],\n",
       "    'layout': {'margin': {'b': 20, 'l': 20, 'r': 20, 't': 20}, 'template': '...'}\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "step = 0\n",
    "bpc_avg = 0\n",
    "bpc_curve = []\n",
    "off_curve = []\n",
    "bpc_win = []\n",
    "\n",
    "sfig = go.FigureWidget()\n",
    "sfig.add_scatter()\n",
    "sfig.update_layout(\n",
    "    margin=dict(l=20, r=20, t=20, b=20),\n",
    ")\n",
    "sfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.train().float().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=2e-4,\n",
    "    betas=(0.9, 0.99),\n",
    "    weight_decay=0.0 # lr / 100\"\n",
    ")\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# model.reset_states()\n",
    "mem = None\n",
    "\n",
    "for data in (prog := tqdm(trainset)):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        outputs, mem = model(data, mem)\n",
    "\n",
    "        targets = data[:, 1:].flatten()\n",
    "        outputs = outputs[:, :-1].flatten(0,1)\n",
    "\n",
    "        loss = loss_func(outputs, targets)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    step += 1\n",
    "    bpc = loss.item() / math.log(2)\n",
    "    bpc_win = bpc_win[-99:] + [bpc]\n",
    "    bpc_avg = sum(bpc_win) / len(bpc_win)\n",
    "    prog.set_description(f'{(bpc_avg):.4f} bpc')\n",
    "\n",
    "    if step % 64 == 0:\n",
    "        bpc_curve += [bpc_avg]\n",
    "        sfig.data[0].y = bpc_curve\n",
    "\n",
    "        for p in model.parameters():\n",
    "            p.data.clamp_(-20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'./model{params}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:10<00:00, 14.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meaning of life is fatal as the Jacob’s great way to the way With a Grandest Street in a hurtwhyed have Tunderloon snowdow. And still a light and last perhaps. The dame dowager’s tay in the dyings and they say. Notorious, there is no strong and if she showed no more scheinish might fall a delltangle. Declare to present. And was theirs to be continued. For as Punch, hand and rarring, rouge. And it was not a boundless either of the younging panes from the bird of the three ballows so was feeling with the forest. Though his free link has a stroke to lay and his frokerfor. But the ruck mack that would she the charmhaloosum? Pass the pipette whereas he lags a toll a tarnpike. Adversarian! The swabsister Kates for the Clunkey soft Danno, she said the shortlegman may have been tourned by the sundawn. And the prankquean went and all the way how it was in the barrel, read the strangewrote anaglyptics of his slow polishments and threehailed concerning and not a few eggs in begging quite having done had he removed at the same time he \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gen = b'The meaning of life is '\n",
    "entropy = 1\n",
    "\n",
    "model.eval().cpu()\n",
    "\n",
    "gen = torch.frombuffer(gen, dtype=torch.uint8)\n",
    "gen = gen.long()[None, :]\n",
    "prev_len = 0\n",
    "mem = None\n",
    "with torch.no_grad():\n",
    "    for t in tqdm(range(200)):\n",
    "        pred, mem = model(gen[:, prev_len:], mem)\n",
    "        pred = pred[0, -1:] / entropy\n",
    "        \n",
    "        choose = torch.multinomial(pred.softmax(dim=-1), 1)\n",
    "        \n",
    "        gen = torch.cat((gen, choose), dim=-1)\n",
    "\n",
    "out = bytes(gen[0].tolist()).decode('utf-8')\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
